{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd4c25dc",
   "metadata": {},
   "source": [
    "# ResNet Tests on Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "066f6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c72d9",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fa641f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "image_dir = \"Images/2048Tiles\"\n",
    "csv_path = \"CSV/Image_Data.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "num_classes = 2\n",
    "class_names = ['0','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e76c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_labels = []\n",
    "class MetastasisDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_path, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Normalize codes (remove dashes/underscores)\n",
    "        df['Code'] = df['Code'].astype(str).str.replace(r'[-_]', '', regex=True)\n",
    "        self.label_map = dict(zip(df['Code'], df['Metastasis'].astype(str)))\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.patient_ids = []\n",
    "        unmatched_images = 0\n",
    "\n",
    "        for fname in os.listdir(image_dir):\n",
    "            # Normalize filename (remove dashes/underscores)\n",
    "            fname_norm = fname.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            matched = False\n",
    "            for pid in self.label_map:\n",
    "                pid_norm = pid.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "                if pid_norm in fname_norm:\n",
    "                    self.image_paths.append(os.path.join(image_dir, fname))\n",
    "                    self.labels.append(int(self.label_map[pid]))\n",
    "                    self.patient_ids.append(pid)\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                unmatched_images+=1\n",
    "                unmatched_labels.append(fname)\n",
    "        print(f'Number of images that were not matched = {unmatched_images}')\n",
    "        print(f\"Loaded {len(self.image_paths)} labeled images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        patient_id = self.patient_ids[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, patient_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950c79a",
   "metadata": {},
   "source": [
    "# Transforms & Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9140c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images that were not matched = 5805\n",
      "Loaded 52029 labeled images.\n",
      "Train patients: 126\n",
      "Val patients: 32\n",
      "Overlap: set()\n",
      "Train label counts:\n",
      " label\n",
      "1    23998\n",
      "0    18553\n",
      "Name: count, dtype: int64\n",
      "Val label counts:\n",
      " label\n",
      "1    5539\n",
      "0    3939\n",
      "Name: count, dtype: int64\n",
      "Number of images that were not matched = 5805\n",
      "Loaded 52029 labeled images.\n",
      "Number of images that were not matched = 5805\n",
      "Loaded 52029 labeled images.\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = MetastasisDataset(image_dir=image_dir, csv_path=csv_path, transform=val_transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_paths, val_paths, train_labels, val_labels, train_ids, val_ids = train_test_split(\n",
    "    full_dataset.image_paths,\n",
    "    full_dataset.labels,\n",
    "    full_dataset.patient_ids,\n",
    "    test_size=0.2,\n",
    "    stratify=full_dataset.labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Patient ID workaround begin code:\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"image_path\": full_dataset.image_paths,\n",
    "    \"label\": full_dataset.labels,\n",
    "    \"patient_id\": full_dataset.patient_ids\n",
    "})\n",
    "\n",
    "patient_labels = df.groupby(\"patient_id\")[\"label\"].max().reset_index()\n",
    "\n",
    "train_patients, val_patients = train_test_split(\n",
    "    patient_labels[\"patient_id\"],\n",
    "    test_size=0.2,\n",
    "    stratify=patient_labels[\"label\"],  # stratify by patient-level label\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df[df[\"patient_id\"].isin(train_patients)]\n",
    "val_df   = df[df[\"patient_id\"].isin(val_patients)]\n",
    "\n",
    "# Sanity check\n",
    "print(\"Train patients:\", train_df[\"patient_id\"].nunique())\n",
    "print(\"Val patients:\", val_df[\"patient_id\"].nunique())\n",
    "print(\"Overlap:\", set(train_df[\"patient_id\"]) & set(val_df[\"patient_id\"]))  # should be empty\n",
    "print(\"Train label counts:\\n\", train_df[\"label\"].value_counts())\n",
    "print(\"Val label counts:\\n\", val_df[\"label\"].value_counts())\n",
    "\n",
    "### Old code\n",
    "\n",
    "'''\n",
    "# Wrap back into Dataset objects\n",
    "train_dataset = MetastasisDataset(image_dir=image_dir, csv_path=csv_path, transform=train_transform)\n",
    "train_dataset.image_paths, train_dataset.labels, train_dataset.patient_ids = train_paths, train_labels, train_ids\n",
    "\n",
    "val_dataset = MetastasisDataset(image_dir=image_dir, csv_path=csv_path, transform=val_transform)\n",
    "val_dataset.image_paths, val_dataset.labels, val_dataset.patient_ids = val_paths, val_labels, val_ids\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Val dataset size: {len(val_dataset)}\")\n",
    "'''\n",
    "\n",
    "# New Code\n",
    "train_dataset = MetastasisDataset(image_dir=image_dir, csv_path=csv_path, transform=train_transform)\n",
    "train_dataset.image_paths  = train_df[\"image_path\"].tolist()\n",
    "train_dataset.labels       = train_df[\"label\"].tolist()\n",
    "train_dataset.patient_ids  = train_df[\"patient_id\"].tolist()\n",
    "\n",
    "val_dataset = MetastasisDataset(image_dir=image_dir, csv_path=csv_path, transform=val_transform)\n",
    "val_dataset.image_paths    = val_df[\"image_path\"].tolist()\n",
    "val_dataset.labels         = val_df[\"label\"].tolist()\n",
    "val_dataset.patient_ids    = val_df[\"patient_id\"].tolist()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a771a468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_list = []\n",
    "for i in train_dataset.patient_ids:\n",
    "    for k in val_dataset.patient_ids:\n",
    "        if i ==k:\n",
    "            patient_list.append(i)\n",
    "        else: pass\n",
    "patient_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f16cc7",
   "metadata": {},
   "source": [
    "### Note to add EL-0 to final CSV file as there are no EL-0xxxxx patients represented. Data on these patients in Onkos_Todo.csv in \"Raw_CSV\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc826fd",
   "metadata": {},
   "source": [
    "# Block for checking class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0c81d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metastasis Count in Full Dataset: 29537\n",
      "Non-Metastatic Count in Full Dataset: 22492\n",
      "Class imbalance in the Full dataset is: 0.5677026273808837 for Metastasis Representation\n",
      "\n",
      "Class Imbalance Count in Train Dataset: 0.5639820450753213\n",
      "Class Imbalance Count in Validation Dataset: 0.5844059928254907\n",
      "\n",
      "Training and Test sets are balanced\n"
     ]
    }
   ],
   "source": [
    "counts = collections.Counter(full_dataset.labels)\n",
    "train_counts = collections.Counter(train_dataset.labels)\n",
    "val_counts = collections.Counter(val_dataset.labels)\n",
    "\n",
    "print(f'Metastasis Count in Full Dataset: {counts[1]}')\n",
    "print(f'Non-Metastatic Count in Full Dataset: {counts[0]}')\n",
    "print(f'Class imbalance in the Full dataset is: {counts[1] / (counts[0]+counts[1])} for Metastasis Representation')\n",
    "print()\n",
    "print(f'Class Imbalance Count in Train Dataset: {train_counts[1] / (train_counts[0]+train_counts[1])}')\n",
    "print(f'Class Imbalance Count in Validation Dataset: {val_counts[1] / (val_counts[0]+val_counts[1])}')\n",
    "print()\n",
    "if abs((train_counts[1] / (train_counts[0]+train_counts[1])) - val_counts[1] / (val_counts[0]+val_counts[1])) < 0.03:\n",
    "    print(\"Training and Test sets are balanced\")\n",
    "else:    \n",
    "    print(\"Training and Test sets are not balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b647",
   "metadata": {},
   "source": [
    "# Getting Pretrained Layers and adding new layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248d845e",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00d62f55-a8f2-4ac6-8563-66d473f49040",
   "metadata": {},
   "source": [
    "feature_extract = True \n",
    "\n",
    "model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "\n",
    "if feature_extract:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 256),   \n",
    "    nn.ReLU(),                              \n",
    "    nn.Dropout(0.5),                        \n",
    "    nn.Linear(256, num_classes)            \n",
    ")\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "model.to(device)\n",
    "print(f\"ResNet34 Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54755ea5-8c54-43bc-a64e-29712bf74b6a",
   "metadata": {},
   "source": [
    "#### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad27d5a7-3a67-4f2b-8eb7-f71be1e09fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet_option(num=201):\n",
    "    match num:\n",
    "        case 121:\n",
    "            return models.densenet121(weights=models.DenseNet121_Weights.DEFAULT), \"DenseNet121\"\n",
    "        case 169:\n",
    "            return models.densenet169(weights=models.DenseNet169_Weights.DEFAULT), \"DenseNet169\"\n",
    "        case 201:\n",
    "            return models.densenet201(weights=models.DenseNet201_Weights.DEFAULT), \"DenseNet201\"\n",
    "        case 264:\n",
    "            return models.densenet264(weights=models.DenseNet264_Weights.DEFAULT), \"DenseNet264\"\n",
    "\n",
    "\n",
    "def freeze_all_except(model, train_blocks=None, train_classifier=True):\n",
    "    \"\"\"\n",
    "    train_blocks: list of block indices you want to train, e.g. [4] or [3,4]\n",
    "    train_classifier: True/False — whether classifier is trainable\n",
    "    \"\"\"\n",
    "    # First freeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Train classifier (optional)\n",
    "    if train_classifier:\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Train selected DenseNet blocks\n",
    "    if train_blocks is not None:\n",
    "        for block_num in train_blocks:\n",
    "            block_name = f\"denseblock{block_num}\"\n",
    "            block = getattr(model.features, block_name, None)\n",
    "            if block is not None:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = True\n",
    "            else:\n",
    "                print(f\"[Warning] {block_name} not found in model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "713cf9f4-3789-48da-9d66-2d6f3e5eb1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet201 Parameters: 7,470,850\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# Select the DenseNet Variant select from [121, 169, 201, 264]\n",
    "# model, densenet_name = densenet_option(169) - example\n",
    "model, densenet_name = densenet_option(201)\n",
    "\n",
    "# Replace classifier - customizes the classifier\n",
    "# returns pretrained features to be used as input into classifier\n",
    "# to remap\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, num_classes)             \n",
    ")\n",
    "\n",
    "# ======== APPLY DENSENET ABLATION HERE =========\n",
    "# OPTIONS:\n",
    "#freeze_all_except(model, train_blocks=[], train_classifier=True)   # Only classifier\n",
    "freeze_all_except(model, train_blocks=[4])        # Train only DenseBlock4 + classifier\n",
    "#freeze_all_except(model, train_blocks=[3,4])   # Train DenseBlock3 + DenseBlock4 + classifier\n",
    "#freeze_all_except(model, train_blocks=[2,3,4]) # Train last DenseBlock2 + DenseBlock3 +DenseBlock4 + classifier\n",
    "# ===============================================\n",
    "\n",
    "# Move model to device, device set in Data Loader - CPU or GPU\n",
    "model.to(device)\n",
    "print(f\"{densenet_name} Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663afe42",
   "metadata": {},
   "source": [
    "# Training Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67cc753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels, _ in tqdm(dataloader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            # Get probabilities for positive class\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "    \n",
    "    # Calculate AUROC and AUPRC\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    auprc = average_precision_score(all_labels, all_probs)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, cm, report, auroc, auprc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train and evaluate a model.\n",
    "    Returns:\n",
    "        Dictionary with training history\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 30)\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, cm, report, val_auroc, val_auprc = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_test_set(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and print metrics.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL TEST SET EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss, test_acc, cm, report, auroc, auprc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f'\\nTest Loss: {test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "    print(f'Test AUROC: {auroc:.4f}')\n",
    "    print(f'Test AUPRC: {auprc:.4f}')\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return test_loss, test_acc, auroc, auprc\n",
    "    \n",
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    \"\"\"Plot training and validation loss/accuracy.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    ax1.plot(history['train_loss'], label='Train Loss')\n",
    "    ax1.plot(history['val_loss'], label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'{title} - Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history['train_acc'], label='Train Acc')\n",
    "    ax2.plot(history['val_acc'], label='Val Acc')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.set_title(f'{title} - Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33bd5d",
   "metadata": {},
   "source": [
    "# Executive Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aae723b-063a-4d76-bd38-cfa33e3e2ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing Pretrained ResNet34 on Image Slides\n",
      "============================================================\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2660/2660 [05:15<00:00,  8.43it/s]\n",
      "Evaluating: 100%|██████████| 593/593 [00:53<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4289, Train Acc: 79.72%\n",
      "Val Loss: 0.4640, Val Acc: 78.28%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2944  995]\n",
      " [1064 4475]]\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▍     | 1169/2660 [02:33<03:15,  7.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m results = {}\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Train on train/val sets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     results[\u001b[33m\"\u001b[39m\u001b[33mResNet34\u001b[39m\u001b[33m\"\u001b[39m] = history[\u001b[33m\"\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n\u001b[32m     12\u001b[39m     plot_training_history(history, \u001b[33m\"\u001b[39m\u001b[33mResNet34\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, lr)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m train_loss, train_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m val_loss, val_acc, cm, report, val_auroc, val_auprc = evaluate(model, val_loader, criterion, device)\n\u001b[32m     86\u001b[39m history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device)\u001b[39m\n\u001b[32m      5\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m      6\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/apps/software/standard/core/jupyterlab/4.4.6-py3.12/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mMetastasisDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     43\u001b[39m image = Image.open(img_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label, patient_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torchvision/transforms/functional.py:174\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    172\u001b[39m img = img.view(pic.size[\u001b[32m1\u001b[39m], pic.size[\u001b[32m0\u001b[39m], F_pil.get_image_num_channels(pic))\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m img = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.ByteTensor):\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img.to(dtype=default_float_dtype).div(\u001b[32m255\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Testing Pretrained ResNet34 on Image Slides\")\n",
    "    print(\"=\" * 60)\n",
    "    test_epochs = 10\n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        # Train on train/val sets\n",
    "        history = train_model(model, train_loader, val_loader, num_epochs=test_epochs, lr=1e-4)\n",
    "        results[\"ResNet34\"] = history[\"val_acc\"][-1]\n",
    "        plot_training_history(history, \"ResNet34\")\n",
    "        \n",
    "        # ADD THIS: Evaluate on test set\n",
    "        test_loss, test_acc, test_auroc, test_auprc = evaluate_test_set(model, val_loader, device)\n",
    "        results[\"ResNet34_test_acc\"] = test_acc\n",
    "        results[\"ResNet34_test_auroc\"] = test_auroc\n",
    "        results[\"ResNet34_test_auprc\"] = test_auprc\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ResNet34: {e}\")\n",
    "        results[\"ResNet34\"] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de6643-fd45-4be8-9014-4dc6adca183a",
   "metadata": {},
   "source": [
    "# Sifting Val Loader to find Specific Proteins (For testing on specifics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8bcd5f3-ebe9-43ce-b1af-a0d2f930965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import os\n",
    "\n",
    "def get_stain_loader(original_loader, stain_name):\n",
    "    \"\"\"\n",
    "    Create a new loader with only specified stain (keeps original intact).\n",
    "    \n",
    "    Args:\n",
    "        original_loader: Existing DataLoader\n",
    "        stain_name: Stain to filter for\n",
    "    \n",
    "    Returns:\n",
    "        New DataLoader with filtered subset\n",
    "    \"\"\"\n",
    "    dataset = original_loader.dataset\n",
    "    \n",
    "    # Find indices matching the stain\n",
    "    stain_indices = []\n",
    "    for idx, path in enumerate(dataset.image_paths):\n",
    "        filename = os.path.basename(path)\n",
    "        if stain_name.upper() in filename.upper():\n",
    "            stain_indices.append(idx)\n",
    "    \n",
    "    print(f\"{stain_name}: {len(stain_indices)} images found\")\n",
    "    \n",
    "    # Create subset\n",
    "    subset = Subset(dataset, stain_indices)\n",
    "    \n",
    "    # Create new loader\n",
    "    stain_loader = DataLoader(\n",
    "        subset, \n",
    "        batch_size=original_loader.batch_size, \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return stain_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b824475-0756-467c-8a0d-c1d6c8cbea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE: 1416 images found\n",
      "MITF: 1782 images found\n",
      "ANX: 1182 images found\n",
      "BCL2: 1240 images found\n",
      "BCL3: 1194 images found\n",
      "PBP: 1303 images found\n",
      "PIR: 1319 images found\n",
      "Original val_loader: 9478 images\n",
      "HE-only loader: 1416 images\n",
      "\n",
      "============================================================\n",
      "FINAL TEST SET EVALUATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 74/74 [00:05<00:00, 13.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.7044\n",
      "Test Accuracy: 73.52%\n",
      "Test AUROC: 0.7814\n",
      "Test AUPRC: 0.8439\n",
      "\n",
      "Confusion Matrix:\n",
      "[[262 189]\n",
      " [124 607]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6788    0.5809    0.6260       451\n",
      "           1     0.7626    0.8304    0.7950       731\n",
      "\n",
      "    accuracy                         0.7352      1182\n",
      "   macro avg     0.7207    0.7057    0.7105      1182\n",
      "weighted avg     0.7306    0.7352    0.7305      1182\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loader_he = get_stain_loader(val_loader, 'HE')\n",
    "val_loader_mitf = get_stain_loader(val_loader, 'MITF')\n",
    "val_loader_anx = get_stain_loader(val_loader, 'ANX')\n",
    "val_loader_bcl2 = get_stain_loader(val_loader, 'BCL2')\n",
    "val_loader_bcl3 = get_stain_loader(val_loader, 'BCL3')\n",
    "val_loader_pbp = get_stain_loader(val_loader, 'PBP')\n",
    "val_loader_pir = get_stain_loader(val_loader, 'PIR')\n",
    "\n",
    "print(f\"Original val_loader: {len(val_loader.dataset)} images\")\n",
    "print(f\"HE-only loader: {len(val_loader_he.dataset)} images\")\n",
    "\n",
    "test_loss, test_acc, test_auroc, test_auprc = evaluate_test_set(model, val_loader_anx, device)\n",
    "results[\"ResNet34_test_acc\"] = test_acc\n",
    "results[\"ResNet34_test_auroc\"] = test_auroc\n",
    "results[\"ResNet34_test_auprc\"] = test_auprc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e45370-3aaa-465a-9ee0-4a773c523021",
   "metadata": {},
   "source": [
    "# Begin Code to Evaluate Logits and Softmax for Patient level classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "478fe7db-02cc-4ff3-9f98-e2280b06846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_by_patient_comprehensive(df, patient_id_length=-8):\n",
    "    \"\"\"\n",
    "    Aggregate predictions by patient with comprehensive checks and statistics.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with patch-level predictions\n",
    "        patient_id_length: Number of characters from filename to use as patient ID\n",
    "    \n",
    "    Returns:\n",
    "        aggregated_df: DataFrame with patient-level predictions\n",
    "    \"\"\"\n",
    "    # Extract patient ID\n",
    "    df['patient_id'] = df['filename'].str[:patient_id_length]\n",
    "    \n",
    "    # Check for label consistency within patients\n",
    "    label_check = df.groupby('patient_id')['true_label'].nunique()\n",
    "    inconsistent = label_check[label_check > 1]\n",
    "    if len(inconsistent) > 0:\n",
    "        print(f\"WARNING: {len(inconsistent)} patients have inconsistent labels across patches!\")\n",
    "        print(inconsistent)\n",
    "    \n",
    "    # Aggregate\n",
    "    aggregated = df.groupby('patient_id').agg({\n",
    "        'true_label': lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0],  # Most common label\n",
    "        'prob_no_metastasis': 'mean',\n",
    "        'prob_metastasis': 'mean',\n",
    "        'predicted_class': 'count'  # Will be renamed to num_patches\n",
    "    }).reset_index()\n",
    "    \n",
    "    aggregated.rename(columns={'predicted_class': 'num_patches'}, inplace=True)\n",
    "    \n",
    "    # Create predicted class based on averaged probabilities\n",
    "    aggregated['predicted_class'] = (aggregated['prob_metastasis'] > aggregated['prob_no_metastasis']).astype(int)\n",
    "    \n",
    "    # Confidence is the max probability\n",
    "    aggregated['confidence'] = aggregated[['prob_no_metastasis', 'prob_metastasis']].max(axis=1)\n",
    "    \n",
    "    # Correctness\n",
    "    aggregated['correct'] = (aggregated['predicted_class'] == aggregated['true_label']).astype(int)\n",
    "    \n",
    "    # Reorder columns\n",
    "    aggregated = aggregated[[\n",
    "        'patient_id',\n",
    "        'num_patches',\n",
    "        'true_label',\n",
    "        'predicted_class',\n",
    "        'prob_no_metastasis',\n",
    "        'prob_metastasis',\n",
    "        'confidence',\n",
    "        'correct'\n",
    "    ]]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "    \n",
    "    accuracy = aggregated['correct'].mean() * 100\n",
    "    auroc = roc_auc_score(aggregated['true_label'], aggregated['prob_metastasis'])\n",
    "    cm = confusion_matrix(aggregated['true_label'], aggregated['predicted_class'])\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"PATIENT-LEVEL AGGREGATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total patches: {len(df)}\")\n",
    "    print(f\"Total patients: {len(aggregated)}\")\n",
    "    print(f\"Avg patches/patient: {aggregated['num_patches'].mean():.1f} (min: {aggregated['num_patches'].min()}, max: {aggregated['num_patches'].max()})\")\n",
    "    print(f\"\\nPatient-level accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Patient-level AUROC: {auroc:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"                 Predicted\")\n",
    "    print(f\"               No Met  Metastasis\")\n",
    "    print(f\"True No Met      {cm[0,0]:4d}    {cm[0,1]:4d}\")\n",
    "    print(f\"True Metastasis  {cm[1,0]:4d}    {cm[1,1]:4d}\")\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(aggregated['true_label'], aggregated['predicted_class'],\n",
    "                                target_names=['No Metastasis', 'Metastasis'],\n",
    "                                digits=4))\n",
    "    \n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb6d0f07-d8ed-444f-89ae-7ddd08c82b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing patch-level predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing patches:  48%|████▊     | 286/593 [00:26<00:28, 10.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m patch_df = \u001b[43msave_patch_predictions_to_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpatch_level_predictions.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     83\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Then aggregate to patient level\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[88]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36msave_patch_predictions_to_csv\u001b[39m\u001b[34m(model, dataloader, device, output_csv)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComputing patch-level predictions...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProcessing patches\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/apps/software/standard/core/jupyterlab/4.4.6-py3.12/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mMetastasisDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     43\u001b[39m image = Image.open(img_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label, patient_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torchvision/transforms/functional.py:168\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[32m    167\u001b[39m mode_to_nptype = {\u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m\"\u001b[39m: np.int32, \u001b[33m\"\u001b[39m\u001b[33mI;16\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.byteorder == \u001b[33m\"\u001b[39m\u001b[33mlittle\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mI;16B\u001b[39m\u001b[33m\"\u001b[39m: np.int16, \u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m: np.float32}\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m img = torch.from_numpy(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pic.mode == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    171\u001b[39m     img = \u001b[32m255\u001b[39m * img\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def save_patch_predictions_to_csv(model, dataloader, device, output_csv='patch_level_predictions.csv'):\n",
    "    \"\"\"\n",
    "    Save individual patch predictions to CSV (handles both Dataset and Subset).\n",
    "    \n",
    "    Args:\n",
    "        model: Trained CNN model\n",
    "        dataloader: DataLoader containing validation data\n",
    "        device: torch device\n",
    "        output_csv: Path to save CSV file\n",
    "    \n",
    "    Returns:\n",
    "        df: DataFrame with patch-level predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    csv_data = []\n",
    "    \n",
    "    # Handle Subset vs regular Dataset\n",
    "    dataset = dataloader.dataset\n",
    "    if hasattr(dataset, 'dataset'):\n",
    "        # It's a Subset, get the underlying dataset\n",
    "        original_dataset = dataset.dataset\n",
    "        indices = dataset.indices\n",
    "    else:\n",
    "        # It's a regular dataset\n",
    "        original_dataset = dataset\n",
    "        indices = range(len(dataset))\n",
    "    \n",
    "    print(\"Computing patch-level predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels, patient_ids) in enumerate(tqdm(dataloader, desc=\"Processing patches\")):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Get raw logits\n",
    "            logits = model(inputs)\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            \n",
    "            # Process each image in the batch\n",
    "            for i in range(len(labels)):\n",
    "                # Get the actual dataset index\n",
    "                sample_idx = batch_idx * dataloader.batch_size + i\n",
    "                if sample_idx < len(indices):\n",
    "                    actual_idx = indices[sample_idx]\n",
    "                    \n",
    "                    # Get filename from original dataset\n",
    "                    img_path = original_dataset.image_paths[actual_idx]\n",
    "                    filename = os.path.basename(img_path)\n",
    "                    \n",
    "                    # Add to CSV data\n",
    "                    csv_data.append({\n",
    "                        'filename': filename,\n",
    "                        'true_label': labels[i].item(),\n",
    "                        'predicted_class': predicted[i].item(),\n",
    "                        'prob_no_metastasis': probs[i, 0].item(),\n",
    "                        'prob_metastasis': probs[i, 1].item(),\n",
    "                        'confidence': probs[i, predicted[i]].item(),\n",
    "                        'correct': int(predicted[i].item() == labels[i].item())\n",
    "                    })\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"\\n✓ Saved {len(df)} patch predictions to: {output_csv}\")\n",
    "    print(f\"\\nCSV Preview:\")\n",
    "    print(df.head(10).to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Usage\n",
    "patch_df = save_patch_predictions_to_csv(\n",
    "    model=model,\n",
    "    dataloader=val_loader,\n",
    "    device=device,\n",
    "    output_csv='patch_level_predictions.csv'\n",
    ")\n",
    "\n",
    "# Then aggregate to patient level\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Aggregating to patient level...\")\n",
    "patient_df = aggregate_by_patient_comprehensive(patch_df, patient_id_length=11)\n",
    "patient_df.to_csv('he_patient_level_predictions.csv', index=False)\n",
    "print(\"✓ Saved patient-level predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adf26c42-11be-4ce0-a88d-6bc714b1c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('patch_level_predictions.csv')\n",
    "df = df.sort_values(by='filename')\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b80c61-05c6-4790-986d-fca07f5a803f",
   "metadata": {},
   "source": [
    "# Check Metrics After Consolodating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "873509f7-6b02-4c4c-a131-a3486d9895f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before aggregation:\n",
      "  Total patches: 9478\n",
      "  Unique filenames: 9478\n",
      "\n",
      "✓ Aggregated 9478 patches into 9478 patients\n",
      "  Avg patches/patient: 1.0\n",
      "  Patient-level accuracy: 75.40%\n",
      "\n",
      "Verification:\n",
      "  Patches in original: 9478\n",
      "  Patches in aggregated (sum): 9478\n",
      "  Match: True\n",
      "\n",
      "⚠️  9478 patients have only 1 patch:\n",
      "                                       patient_id  \\\n",
      "0  ast_b28775-anx - 2018-05-28 15.23.57_slide_10.   \n",
      "1  ast_b28775-anx - 2018-05-28 15.23.57_slide_12.   \n",
      "2  ast_b28775-anx - 2018-05-28 15.23.57_slide_13.   \n",
      "3  ast_b28775-anx - 2018-05-28 15.23.57_slide_14.   \n",
      "4  ast_b28775-anx - 2018-05-28 15.23.57_slide_15.   \n",
      "5  ast_b28775-anx - 2018-05-28 15.23.57_slide_16.   \n",
      "6  ast_b28775-anx - 2018-05-28 15.23.57_slide_17.   \n",
      "7  ast_b28775-anx - 2018-05-28 15.23.57_slide_18.   \n",
      "8  ast_b28775-anx - 2018-05-28 15.23.57_slide_19.   \n",
      "9   ast_b28775-anx - 2018-05-28 15.23.57_slide_2.   \n",
      "\n",
      "                                     sample_filename  \n",
      "0  AST_B28775-ANX - 2018-05-28 15.23.57_slide_10.png  \n",
      "1  AST_B28775-ANX - 2018-05-28 15.23.57_slide_12.png  \n",
      "2  AST_B28775-ANX - 2018-05-28 15.23.57_slide_13.png  \n",
      "3  AST_B28775-ANX - 2018-05-28 15.23.57_slide_14.png  \n",
      "4  AST_B28775-ANX - 2018-05-28 15.23.57_slide_15.png  \n",
      "5  AST_B28775-ANX - 2018-05-28 15.23.57_slide_16.png  \n",
      "6  AST_B28775-ANX - 2018-05-28 15.23.57_slide_17.png  \n",
      "7  AST_B28775-ANX - 2018-05-28 15.23.57_slide_18.png  \n",
      "8  AST_B28775-ANX - 2018-05-28 15.23.57_slide_19.png  \n",
      "9   AST_B28775-ANX - 2018-05-28 15.23.57_slide_2.png  \n"
     ]
    }
   ],
   "source": [
    "# Before aggregation\n",
    "print(\"Before aggregation:\")\n",
    "print(f\"  Total patches: {len(df)}\")\n",
    "print(f\"  Unique filenames: {df['filename'].nunique()}\")\n",
    "\n",
    "# After aggregation\n",
    "patient_df = aggregate_by_patient_robust(df, trim_chars=3)\n",
    "\n",
    "# Verify no data loss\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"  Patches in original: {len(df)}\")\n",
    "print(f\"  Patches in aggregated (sum): {patient_df['num_patches'].sum()}\")\n",
    "print(f\"  Match: {len(df) == patient_df['num_patches'].sum()}\")\n",
    "\n",
    "# Check for any patients with only 1 patch (might be suspicious)\n",
    "single_patch = patient_df[patient_df['num_patches'] == 1]\n",
    "if len(single_patch) > 0:\n",
    "    print(f\"\\n⚠️  {len(single_patch)} patients have only 1 patch:\")\n",
    "    print(single_patch[['patient_id', 'sample_filename']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91a805e6-6f1d-4667-875e-18da9617b021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Aggregated 9478 patches into 9478 patients\n",
      "  Avg patches/patient: 1.0\n",
      "  Patient-level accuracy: 75.40%\n"
     ]
    }
   ],
   "source": [
    "def aggregate_by_patient_robust(df, trim_chars=3, case_sensitive=False):\n",
    "    \"\"\"\n",
    "    Robust patient aggregation with error handling.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with patch-level predictions\n",
    "        trim_chars: Number of characters to remove from end (use 0 for none)\n",
    "        case_sensitive: Whether patient IDs should be case-sensitive\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle null/empty filenames\n",
    "    df = df[df['filename'].notna() & (df['filename'] != '')]\n",
    "    \n",
    "    # Extract patient ID\n",
    "    if trim_chars > 0:\n",
    "        # Check if any filenames are too short\n",
    "        too_short = df['filename'].str.len() <= trim_chars\n",
    "        if too_short.any():\n",
    "            print(f\"⚠️  WARNING: {too_short.sum()} filenames are too short, skipping trim for those\")\n",
    "            df['patient_id'] = df.apply(\n",
    "                lambda row: row['filename'][:-trim_chars] if len(row['filename']) > trim_chars else row['filename'],\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            df['patient_id'] = df['filename'].str[:-trim_chars]\n",
    "    else:\n",
    "        df['patient_id'] = df['filename']\n",
    "    \n",
    "    # Strip whitespace\n",
    "    df['patient_id'] = df['patient_id'].str.strip()\n",
    "    \n",
    "    # Convert to lowercase if not case-sensitive\n",
    "    if not case_sensitive:\n",
    "        df['patient_id'] = df['patient_id'].str.lower()\n",
    "    \n",
    "    # Check for label inconsistencies\n",
    "    label_check = df.groupby('patient_id')['true_label'].nunique()\n",
    "    inconsistent = label_check[label_check > 1]\n",
    "    if len(inconsistent) > 0:\n",
    "        print(f\"⚠️  WARNING: {len(inconsistent)} patients have inconsistent labels!\")\n",
    "        for pid in inconsistent.index:\n",
    "            labels = df[df['patient_id'] == pid]['true_label'].unique()\n",
    "            print(f\"   {pid}: {labels}\")\n",
    "    \n",
    "    # Aggregate\n",
    "    aggregated = df.groupby('patient_id').agg({\n",
    "        'true_label': lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0],  # Most common\n",
    "        'prob_no_metastasis': 'mean',\n",
    "        'prob_metastasis': 'mean',\n",
    "        'filename': ['count', 'first']  # Count and sample filename\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    aggregated.columns = ['patient_id', 'true_label', 'prob_no_metastasis', \n",
    "                         'prob_metastasis', 'num_patches', 'sample_filename']\n",
    "    \n",
    "    # Predicted class\n",
    "    aggregated['predicted_class'] = (aggregated['prob_metastasis'] > aggregated['prob_no_metastasis']).astype(int)\n",
    "    \n",
    "    # Confidence and correctness\n",
    "    aggregated['confidence'] = aggregated[['prob_no_metastasis', 'prob_metastasis']].max(axis=1)\n",
    "    aggregated['correct'] = (aggregated['predicted_class'] == aggregated['true_label']).astype(int)\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n✓ Aggregated {len(df)} patches into {len(aggregated)} patients\")\n",
    "    print(f\"  Avg patches/patient: {aggregated['num_patches'].mean():.1f}\")\n",
    "    print(f\"  Patient-level accuracy: {aggregated['correct'].mean() * 100:.2f}%\")\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "\n",
    "# Usage\n",
    "patient_df = aggregate_by_patient_robust(df, trim_chars=3, case_sensitive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c5d4c-416b-4502-a22a-380ac0c0613c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
